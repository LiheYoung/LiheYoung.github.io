<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lihe Yang</title>
  
  <meta name="author" content="Lihe Yang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/hku_icon.jpeg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Lihe Yang</name>
              </p>
              <p> I am an incoming Ph.D. student at 
                <a href="https://www.hku.hk/">The University of Hong Kong</a> in the Department of Computer Science, fortunately supervised by Prof. <a href="https://hszhao.github.io/">Hengshuang Zhao</a>. 
              </p>
              <p> I received my Bachelor and Master degree from Nanjing University in 2020 and 2023 respectively, fortunately supervised by Prof. <a href="https://cs.nju.edu.cn/shiyh/index.htm">Yinghuan Shi</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:lihe.yang.cs@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=QX7xv3UAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/LiheYoung">Github</a>
              </p>
            </td>
            <!-- <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/daiyongxing.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/daiyongxing.png" class="hoverZoomLink"></a>
            </td> -->
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/LiheYang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/LiheYang.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
	          <p>
              <strong>2023-02:</strong> Two papers on semi-supervised semantic segmentation are accepted by CVPR 2023.
            </p>
            <p>
              <strong>2023-02:</strong> I am awarded the <a href="https://gradsch.hku.hk/prospective_students/fees_scholarships_and_financial_support/hku_presidential_phd_scholar_programme">HKU Presidential PhD Scholarship</a>.
            </p>
	          <p>
              <strong>2022-09:</strong> I join <a href="https://www.shlab.org.cn/">Shanghai AI Lab</a> as a research intern.
            </p>
            <p>
              <strong>2022-04:</strong> I join <a href="https://www.sensetime.com/cn">SenseTime</a> as a research intern.
            </p>
            <p>
              <strong>2022-03:</strong> One paper on semi-supervised semantic segmentation is accepted by CVPR 2022.
            </p>
            <p>
              <strong>2021-10:</strong> I am awarded the National Scholarship.
            </p>
            <p>
              <strong>2021-07:</strong> One paper on few-shot segmentation is accepted by ICCV 2021 as an oral presentation.
            </p>
            
          </td>
        </tr>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Publications</heading>
            <p>
            </p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/unimatch.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2208.09910">
              <papertitle>Revisiting Weak-to-Strong Consistency in Semi-Supervised Semantic Segmentation</papertitle>
            </a>
            <br>
            <strong>Lihe Yang</strong>, Lei Qi, Litong Feng, Wayne Zhang, Yinghuan Shi
            <br>
            <em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2208.09910">Paper</a> |
            <a href="https://github.com/LiheYoung/UniMatch">Code</a> |
            <a href="https://zhuanlan.zhihu.com/p/617650677">Zhihu</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/augseg.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2212.04976">
              <papertitle>Augmentation Matters: A Simple-yet-Effective Approach to Semi-supervised Semantic Segmentation</papertitle>
            </a>
            <br>
            Zhen Zhao, <strong>Lihe Yang</strong>, Sifan Long, Jimin Pi, Luping Zhou, Jingdong Wang
            <br>
            <em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2212.04976">Paper</a> |
            <a href="https://github.com/ZhenZHAO/AugSeg">Code</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/st++.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2106.05095">
              <papertitle>ST++: Make Self-training Work Better for Semi-supervised Semantic Segmentation</papertitle>
            </a>
            <br>
            <strong>Lihe Yang</strong>, Wei Zhuo, Lei Qi, Yinghuan Shi, Yang Gao
            <br>
            <em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2022
            <br>
            <a href="https://arxiv.org/abs/2106.05095">Paper</a> |
            <a href="https://github.com/LiheYoung/ST-PlusPlus">Code</a> |
            <a href="https://zhuanlan.zhihu.com/p/476692814">Zhihu</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/miningfss.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2103.15402">
              <papertitle>Mining Latent Classes for Few-shot Segmentation</papertitle>
            </a>
            <br>
            <strong>Lihe Yang</strong>, Wei Zhuo, Lei Qi, Yinghuan Shi, Yang Gao
            <br>
            <em>IEEE International Conference on Computer Vision (<b>ICCV</b>)</em>, 2021 <b>(Oral)</b>
            <br>
            <a href="https://arxiv.org/abs/2103.15402">Paper</a> |
            <a href="https://github.com/LiheYoung/MiningFSS">Code</a>
          </td>
        </tr>

      </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experiences</heading>
              <p>
                09/2022 - Now, Research Intern at <a href="https://www.shlab.org.cn/">Shanghai AI Lab</a>, supervised by <a href="https://hszhao.github.io/">Prof. Hengshuang Zhao</a>.
              </p>
              <p>
                04/2022 - 09/2022, Research Intern at <a href="https://www.sensetime.com/cn">SenseTime</a>, supervised by <a href="https://scholar.google.com/citations?user=PnNAAasAAAAJ">Dr. Litong Feng</a>.
              </p>
              <p>
                05/2020 - 08/2020, Research Intern at <a href="https://open.youtu.qq.com/#/open">Tencent YouTu Lab</a>, supervised by <a href="https://scholar.google.com/citations?user=Q-UjnzEAAAAJ">Dr. Wei Zhuo</a>.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Contests</heading>
              <p>
                <b>1st Place</b>, SenseTime Remote Sensing Change Detection Competition, 30,000 RMB Bonus, 2020, <a href="https://rs.sensetime.com">Link</a> | <a href="https://github.com/LiheYoung/SenseEarth2020-ChangeDetection">Code</a>
              </p>
              <p>
                <b>2nd Place</b>, The 8th CCF BDCI Remote Sensing Image Segmentation, 20,000 RMB Bonus, 2020, <a href="https://www.datafountain.cn/competitions/475">Link</a>
              </p>
              <p>
                <b>2nd Place</b>, Off Road Image Segmentation Challenge, 200,000 Yen Bonus, 2020, <a href="https://signate.jp/competitions/101">Link</a>
              </p>
              <p>
                <b>2nd Place</b>, BAAI Ultra-high Resolution EM Images Segmentation, 10,000 RMB Bonus, 2019, <a href="https://www.biendata.xyz/competition/urisc/">Link</a> | <a href="https://github.com/LiheYoung/U-RISC">Code</a>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors</heading>
              <p>
                <b>Tencent Scholarship</b>, Nanjing University, 2022
              </p>
              <p>
                <b>First Prize Scholarship for Postgraduate Students</b>, Nanjing University, 2020-2022
              </p>
              <p>
              <b>National Scholarship</b>, Ministry of Education of P.R. China, 2021
              </p>
              <p>
                <b>First Prize of Excellent Undergraduate Thesis</b>, Nanjing University, 2020
              </p>
              <p>
                <b>MICCAI Undergraduate Student Travel Award</b> (a total of 45 recipients around the world), MICCAI, 2019
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Academic Services</heading>
              <p>
                <strong>Conference Reviewer</strong>: CVPR 2022-2023, ICCV 2023, ECCV 2022, NeurIPS 2023, ICLR 2023</a>
              </p>
              <p>
                <strong>Journal Reviewer</strong>: TIP, TNNLS</a>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
